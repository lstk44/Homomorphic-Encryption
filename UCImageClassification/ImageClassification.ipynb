{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Classification\n",
    "\n",
    "**Company Use Case:**\n",
    "\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "\n",
    "\n",
    "The following Notebook will show two approaches to do this with ConcreteML.\n",
    "\n",
    "**Dataset Information:**\n",
    "\n",
    "_Dataset  1:_\n",
    "\n",
    "<span style=\"color:yellow\">description</span>\n",
    "\n",
    "**Dataset Source:**\n",
    "\n",
    "https://medmnist.com/\n",
    "\n",
    "Dataset 1:\n",
    "\n",
    "https://github.com/logpai/loghub/blob/master/Android/Android_2k.log_structured.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MedMNIST\n",
    "import medmnist\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.models import resnet50, vgg16\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PneumoniaMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n",
      "\n",
      " Dataset PneumoniaMNIST (pneumoniamnist)\n",
      "    Number of datapoints: 4708\n",
      "    Root location: /home/lukas/.medmnist\n",
      "    Split: train\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
      "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
      "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "DataClass = getattr(medmnist, dataset)\n",
    "\n",
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# download data\n",
    "train_dataset = DataClass(split='train', transform=transform, download=True)\n",
    "eval_dataset = DataClass(split='val', transform=transform, download=True)\n",
    "test_dataset = DataClass(split='test', transform=transform, download=True)\n",
    "print('\\n', train_dataset)\n",
    "\n",
    "# dataloader\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = data.DataLoader(dataset=eval_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Data\n",
      "\n",
      "Samples:\t4708\n",
      "Channels:\t1\n",
      "Height:\t\t28\n",
      "Width:\t\t28\n"
     ]
    }
   ],
   "source": [
    "# train_dataloader to numpy/tensor array\n",
    "xtrain_np = np.concatenate([batch[0].numpy() for batch in train_loader], axis=0)\n",
    "ytrain_np = np.concatenate([batch[1].numpy() for batch in train_loader], axis=0)\n",
    "\n",
    "# eval_dataloader to numpy/tensor array\n",
    "xval_np = np.concatenate([batch[0].numpy() for batch in eval_loader], axis=0)\n",
    "yval_np = np.concatenate([batch[1].numpy() for batch in eval_loader], axis=0)\n",
    "\n",
    "# test_dataloader to numpy/tensor array\n",
    "xtest_np = np.concatenate([batch[0].numpy() for batch in test_loader], axis=0)\n",
    "ytest_np = np.concatenate([batch[1].numpy() for batch in test_loader], axis=0)\n",
    "\n",
    "print('Numpy Data\\n')\n",
    "print(f'Samples:\\t{xtrain_np.shape[0]}')\n",
    "print(f'Channels:\\t{xtrain_np.shape[1]}')\n",
    "print(f'Height:\\t\\t{xtrain_np.shape[2]}')\n",
    "print(f'Width:\\t\\t{xtrain_np.shape[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 Feature Extraction\n",
    "\n",
    "def feature_extractor(X, model='resnet50'):\n",
    "    # duplicate channels to 3\n",
    "    data = np.repeat(X, 3, axis=1)\n",
    "    # convert to tensor\n",
    "    data = torch.tensor(data, dtype=torch.float)\n",
    "\n",
    "    if model == 'resnet50':\n",
    "        # load pretrained ResNet50\n",
    "        model = resnet50()\n",
    "    elif model == 'vgg16':\n",
    "        # load pretrained VGG16\n",
    "        model = vgg16()\n",
    "    # remove last layer\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    # add flatten layer\n",
    "    model.add_module('flatten', torch.nn.Flatten())\n",
    "    # set model to eval mode\n",
    "    model.eval()\n",
    "    # extract features\n",
    "    with torch.no_grad():\n",
    "        features = model(data).detach().numpy()\n",
    "    # to pandas dataframe\n",
    "    dataframe = pd.DataFrame(features)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_res = feature_extractor(xtrain_np)\n",
    "xval_res = feature_extractor(xval_np)\n",
    "xtest_res = feature_extractor(xtest_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fed0f3aee90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier().fit(xtrain_res, ytrain_np)\n",
    "y_pred = xgb.predict(xtest_res)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(ytest_np, y_pred)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [4708, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test \u001b[39m=\u001b[39m feature_extractor(xtrain_res[[\u001b[39m3\u001b[39;49m]])\n",
      "\u001b[1;32m/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# extract features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     features \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# to pandas dataframe\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lukas/ThesisWSL/Thesis/UCImageClassification/ImageClassification.ipynb#Y201sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [4708, 3]"
     ]
    }
   ],
   "source": [
    "test = feature_extractor(xtrain_res[[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain_tab = feature_extractor(xtrain_res)\n",
    "xval_tab = feature_extractor(xval_res)\n",
    "# xtest_tab = feature_extractor(xtest_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display three sample from each class\n",
    "# fig, ax = plt.subplots(2, 3, figsize=(10, 5))\n",
    "\n",
    "# # get one sample from each class\n",
    "# normal, pneumonia = [], []\n",
    "# for images, labels in train_loader:\n",
    "#     while len(normal) < 3 or len(pneumonia) < 3:\n",
    "#         for i in range(len(labels)):\n",
    "#             if labels[i] == 0 and len(normal) < 3:\n",
    "#                 normal.append(images[i])\n",
    "#             elif labels[i] == 1 and len(pneumonia) < 3:\n",
    "#                 pneumonia.append(images[i])\n",
    "\n",
    "# # display images\n",
    "# for i in range(3):\n",
    "#     ax[0, i].imshow(normal[i].squeeze(), cmap='gray')\n",
    "#     ax[0, i].set_title('Normal')\n",
    "#     ax[0, i].axis('off')\n",
    "#     ax[1, i].imshow(pneumonia[i].squeeze(), cmap='gray')\n",
    "#     ax[1, i].set_title('Pneumonia')\n",
    "#     ax[1, i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader to numpy/tensor array\n",
    "train_images, train_labels = [], []\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    train_images.append(images.numpy())\n",
    "    train_labels.append(labels.numpy())\n",
    "\n",
    "xtrain_np, ytrain_np = np.concatenate(train_images, axis=0), np.concatenate(train_labels, axis=0)\n",
    "xtrain_tensor, ytrain_tensor = torch.FloatTensor(xtrain_np), torch.FloatTensor(ytrain_np)\n",
    "\n",
    "# eval_dataloader to numpy/tensor array\n",
    "eval_images, eval_labels = [], []\n",
    "\n",
    "for batch in eval_loader:\n",
    "    images, labels = batch\n",
    "    eval_images.append(images.numpy())\n",
    "    eval_labels.append(labels.numpy())\n",
    "\n",
    "xval_np, yval_np = np.concatenate(eval_images, axis=0), np.concatenate(eval_labels, axis=0)\n",
    "xval_tensor, yval_tensor = torch.FloatTensor(xval_np), torch.FloatTensor(yval_np)\n",
    "\n",
    "# test_dataloader to numpy/tensor array\n",
    "test_images, test_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    images, labels = batch\n",
    "    test_images.append(images.numpy())\n",
    "    test_labels.append(labels.numpy())\n",
    "\n",
    "xtest_np, ytest_np = np.concatenate(test_images, axis=0), np.concatenate(test_labels, axis=0)\n",
    "xtest_tensor, ytest_tensor = torch.FloatTensor(xtest_np), torch.FloatTensor(ytest_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Samples:\\t{xtrain_np.shape[0]}')\n",
    "print(f'Channels:\\t{xtrain_np.shape[1]}')\n",
    "print(f'Height:\\t\\t{xtrain_np.shape[2]}')\n",
    "print(f'Width:\\t\\t{xtrain_np.shape[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "      torch.nn.Flatten(),\n",
    "      torch.nn.Linear(in_features=169, out_features=1, bias=True),\n",
    "      torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  # training\n",
    "  model.train()\n",
    "  for i in range(0, len(xtrain_tensor), 1):\n",
    "    inputs = xtrain_tensor[i:i+1]\n",
    "    labels = ytrain_tensor[i:i+1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # log metrics\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_outputs = model(xtrain_tensor)\n",
    "    train_loss = criterion(train_outputs, ytrain_tensor)\n",
    "    predicted = torch.round(train_outputs)\n",
    "    train_accuracy = accuracy_score(predicted.detach().numpy(), ytrain_tensor.detach().numpy())*100\n",
    "\n",
    "    val_outputs = model(xval_tensor)\n",
    "    val_loss = criterion(val_outputs, yval_tensor)\n",
    "    predicted = torch.round(val_outputs)\n",
    "    val_accuracy = accuracy_score(predicted.detach().numpy(), yval_tensor.detach().numpy())*100\n",
    "\n",
    "  train_losses.append(train_loss.item())\n",
    "  val_losses.append(val_loss.item())\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(train_losses, label='Training Loss')\n",
    "ax[0].plot(val_losses, label='Validation Loss')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_accuracies, label='Training Accuracy')\n",
    "ax[1].plot(val_accuracies, label='Validation Accuracy')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for i in range(0, len(xtest_tensor), 1):\n",
    "    inputs = xtest_tensor[i:i+1]\n",
    "    labels = ytest_tensor[i:i+1]\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    predicted = torch.round(outputs)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
