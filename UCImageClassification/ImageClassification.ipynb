{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Classification\n",
    "\n",
    "**Company Use Case:**\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "The following Notebook will show two approaches to do this with ConcreteML.\n",
    "\n",
    "**Dataset Source:**\n",
    "\n",
    "The data used is provided by MedMNIST v2, a comprehensive collection of standardized biomedical images. It encompasses 12 datasets for 2D and 6 for 3D images, pre-processed into 28 x 28 (2D) or 28 x 28 x 28 (3D) with corresponding classification labels. With 708,069 2D images and 9,998 3D images, it supports various classification tasks, from binary/multi-class to ordinal regression and multi-label, catering to biomedical image analysis, computer vision, and machine learning research and education.\n",
    "\n",
    "https://medmnist.com/\n",
    "\n",
    "**Dataset  1:**\n",
    "\n",
    "_OCTMNIST_\n",
    "\n",
    "MedMNIST Description:\n",
    "\n",
    "The OCTMNIST is based on a prior dataset of 109,309 valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.\n",
    "\n",
    "https://zenodo.org/records/6496656/files/octmnist.npz?download=1\n",
    "\n",
    "**Dataset 2:**\n",
    "\n",
    "_PneumoniaMNIST_\n",
    "\n",
    "MedMNIST Description:\n",
    "\n",
    "The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
    "\n",
    "https://zenodo.org/records/6496656/files/pneumoniamnist.npz?download=1\n",
    "\n",
    "**Dataset 2:**\n",
    "\n",
    "<span style=\"color:red\">_NAME_</span> (Maybe BloodMNIST)\n",
    "\n",
    "MedMNIST Description:\n",
    "\n",
    "<span style=\"color:red\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHE Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'simulate'\n",
    "\n",
    "# mode = 'execute'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MedMNIST\n",
    "import medmnist\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# XGBoost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, vgg16\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd042676d10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Logging (KICK AFTER BEING DONE)\n",
    "###############################################################\n",
    "\n",
    "def log_parameters():\n",
    "    if os.path.isfile(f'{dataset}_Experiments.csv'):\n",
    "        df = pd.read_csv(f'{dataset}_Experiments.csv')\n",
    "        df = df.drop_duplicates()\n",
    "        # append new row\n",
    "        df = pd.concat([df, pd.DataFrame({\n",
    "            'epochs': [epochs],\n",
    "            'learning_rate': [learning_rate],\n",
    "            'weight_decay': [weight_decay],\n",
    "            'model': [str(model)],\n",
    "            'final_train_loss': [train_losses[-1]],\n",
    "            'final_train_accuracy': [train_accuracies[-1]],\n",
    "            'final_val_loss': [val_losses[-1]],\n",
    "            'final_val_accuracy': [val_accuracies[-1]]\n",
    "            })])\n",
    "        # save csv\n",
    "        df.to_csv(f'{dataset}_Experiments.csv', index=False)\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame({\n",
    "        'epochs': [epochs],\n",
    "        'learning_rate': [learning_rate],\n",
    "        'weight_decay': [weight_decay],\n",
    "        'model': [str(model)],\n",
    "        'final_train_loss': [train_losses[-1]],\n",
    "        'final_train_accuracy': [train_accuracies[-1]],\n",
    "        'final_val_loss': [val_losses[-1]],\n",
    "        'final_val_accuracy': [val_accuracies[-1]]\n",
    "        })\n",
    "        # save csv\n",
    "        df.to_csv(f'{dataset}_Experiments.csv', index=False)\n",
    "    \n",
    "    return 'Parameters Logged!'\n",
    "\n",
    "###############################################################\n",
    "# Load Data\n",
    "###############################################################\n",
    "\n",
    "def load_data(dataset):\n",
    "\n",
    "    '''\n",
    "    Load data from MedMNIST\n",
    "\n",
    "    Input:\n",
    "        dataset (str): name of dataset\n",
    "\n",
    "    Output:\n",
    "    '''\n",
    "\n",
    "    # initialize DataClass\n",
    "    DataClass = getattr(medmnist, dataset)\n",
    "    # download data\n",
    "    train_dataset = DataClass(split='train',download=True)\n",
    "    eval_dataset = DataClass(split='val', download=True)\n",
    "    test_dataset = DataClass(split='test', download=True)\n",
    "    # to numpy array\n",
    "    xtrain, ytrain = train_dataset.imgs, train_dataset.labels\n",
    "    xval, yval = eval_dataset.imgs, eval_dataset.labels\n",
    "    xtest, ytest = test_dataset.imgs, test_dataset.labels\n",
    "    # expand dimension (grayscale)\n",
    "    # (channels=1, height=28, width=28)\n",
    "    xtrain_gray = np.expand_dims(xtrain, axis=1)\n",
    "    xval_gray = np.expand_dims(xval, axis=1)\n",
    "    xtest_gray = np.expand_dims(xtest, axis=1)\n",
    "    # expand dimension (rgb) - needed for pretrained models\n",
    "    # (channels=3, height=28, width=28)\n",
    "    xtrain_rgb = np.repeat(xtrain, 3, axis=1)\n",
    "    xval_rgb = np.repeat(xval, 3, axis=1)\n",
    "    xtest_rgb = np.repeat(xtest, 3, axis=1)\n",
    "\n",
    "    X_grayscale = (xtrain_gray, xval_gray, xtest_gray)\n",
    "    X_rgb = (xtrain_rgb, xval_rgb, xtest_rgb)\n",
    "    y = (ytrain, yval, ytest)\n",
    "\n",
    "    return X_grayscale, X_rgb, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/lukas/.medmnist/pneumoniamnist.npz\n"
     ]
    }
   ],
   "source": [
    "data = load_data(dataset='PneumoniaMNIST')\n",
    "\n",
    "xtrain_gray, xval_gray, xtest_gray = data[0]\n",
    "xtrain_rgb, xval_rgb, xtest_rgb = data[1]\n",
    "ytrain, yval, ytest = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample images of each class\n",
    "n_classes = len(np.unique(ytrain))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=n_classes, figsize=(10, 5))\n",
    "for i in range(n_classes):\n",
    "    ax[i].imshow(xtrain_gray[ytrain.flatten()==i][0][0], cmap='gray')\n",
    "    ax[i].set_title(f'Class {i}')\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tensor, ytrain_tensor = torch.tensor(xtrain, dtype=torch.float), torch.tensor(ytrain, dtype=torch.float)\n",
    "xval_tensor, yval_tensor = torch.tensor(xval, dtype=torch.float), torch.tensor(yval, dtype=torch.float)\n",
    "xtest_tensor, ytest_tensor = torch.tensor(xtest, dtype=torch.float), torch.tensor(ytest, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(ytrain))\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=5),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "      torch.nn.Conv2d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "      torch.nn.Flatten(),\n",
    "      torch.nn.Linear(in_features=256, out_features=1, bias=True),\n",
    "      torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  # training\n",
    "  model.train()\n",
    "  for i in range(0, len(xtrain_tensor), 1):\n",
    "    inputs = xtrain_tensor[i:i+1]\n",
    "    labels = ytrain_tensor[i:i+1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # log metrics\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_outputs = model(xtrain_tensor)\n",
    "    train_loss = criterion(train_outputs, ytrain_tensor)\n",
    "    predicted = torch.round(train_outputs)\n",
    "    train_accuracy = accuracy_score(predicted.detach().numpy(), ytrain_tensor.detach().numpy())*100\n",
    "\n",
    "    val_outputs = model(xval_tensor)\n",
    "    val_loss = criterion(val_outputs, yval_tensor)\n",
    "    predicted = torch.round(val_outputs)\n",
    "    val_accuracy = accuracy_score(predicted.detach().numpy(), yval_tensor.detach().numpy())*100\n",
    "\n",
    "  train_losses.append(train_loss.item())\n",
    "  val_losses.append(val_loss.item())\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(train_losses, label='Training Loss')\n",
    "ax[0].plot(val_losses, label='Validation Loss')\n",
    "ax[0].set_xticks(np.arange(0, epochs, 1))\n",
    "ax[0]. set_xlabel('Epochs')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_accuracies, label='Training Accuracy')\n",
    "ax[1].plot(val_accuracies, label='Validation Accuracy')\n",
    "ax[1].set_xticks(np.arange(0, epochs, 1))\n",
    "ax[1]. set_xlabel('Epochs')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_parameters()\n",
    "\n",
    "pd.read_csv(f'{dataset}_Experiments.csv').sort_values(by='final_val_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Feature Extractor (Transfer Learning) & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check how image looks like after resnet50 preprocessing\n",
    "# x = train_dataset[0][0][0]\n",
    "# plt.imshow(x, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# # resnet50 preprocessing\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[.5], std=[.5])\n",
    "# ])\n",
    "\n",
    "# # resnet50 preprocessing\n",
    "# x = preprocess(x)\n",
    "# plt.imshow(x[0], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
